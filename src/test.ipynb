{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('py38jupyter': conda)",
      "metadata": {
        "interpreter": {
          "hash": "ab9111e2d1eb7638a6ee3590029ebb66ef2184c5b4604a96c97d54fc911db079"
        }
      }
    },
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bellaroseee/447-Group-Project/blob/checkpoint-2/src/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cTu7X1Ujagx"
      },
      "source": [
        "taken from [link](https://keras.io/examples/generative/lstm_character_level_text_generation/)\n",
        "  \n",
        "data from [link](https://www.kaggle.com/namanj27/astronomers-telegram-dataset?select=Processed_Atels.csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcF6qaOtjag1"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e314meGxjag3"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import io\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlHLtqH-jag4"
      },
      "source": [
        "# Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-SlUdHlkWiz"
      },
      "source": [
        "path_to_file = keras.utils.get_file(\r\n",
        "    \"Processed_Atels\", \r\n",
        "    \"https://raw.githubusercontent.com/bellaroseee/447-Group-Project/checkpoint-2/src/Processed_Atels.csv\")\r\n",
        "data = pd.read_csv(path_to_file)\r\n",
        "data = data[\"Text processed\"]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WbnhAyKGZLt",
        "outputId": "6d10ff81-f9d4-49e1-d6d9-0506bd584deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "data[0]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'We report spectroscopic observations of AT2018lab, discovered by the DLT40 survey on UT 2018 Dec 29.13 in the luminous infrared galaxy (LIRG) IC 2163. The observations were performed using the FLOYDS spectrograph on Faulkes-South on UT 2018 Dec 29.46. The spectrum reveals a mostly featureless blue continuum. We also note the presence of H-alpha emission in our spectrum with FWHM of 400 km/s. This feature could be associated with the host galaxy IC 2163, but is blueshifted from the nominal recessional velocity of the host by 600 km/s.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKgmCnHbGtJp",
        "outputId": "b052d0a5-95e4-4a5f-c6b4-7b41a889426d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1203"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfy42bVhHdr1",
        "outputId": "4ab315b5-63aa-40c9-a18a-7e44956aa0b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_data = data[:10]\r\n",
        "dev_data = data[10:20]\r\n",
        "train_data = data[20:]\r\n",
        "print(f\"test: {len(test_data)}\\ndev: {len(dev_data)}\\ntrain: {len(train_data)}\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test: 10\n",
            "dev: 10\n",
            "train: 1183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87zx22Uyjag5",
        "outputId": "28d4f061-6900-4827-ce62-efa7d1a00561"
      },
      "source": [
        "# text_processed = data[\"Text processed\"]\n",
        "text = \"\"\n",
        "for row in text_processed:\n",
        "    text += row\n",
        "\n",
        "print(\"Corpus length:\", len(text))\n",
        "chars = sorted(list(set(text)))\n",
        "print(\"Total chars:\", len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "print(len(list(char_indices)))\n",
        "# char_indices maps character to index (index is decided here)\n",
        "# indices_char maps index to character (this is the opposite of char_indices)\n",
        "\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i : i + maxlen]) # add 40 chars from i to sentences\n",
        "    next_chars.append(text[i + maxlen]) # add the next char to next_chars\n",
        "print(\"Number of sequences:\", len(sentences))\n",
        "\n",
        "# test = 1\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    # if (test == 1) :\n",
        "      # print(i, sentence)\n",
        "      for t, char in enumerate(sentence):\n",
        "          # print(t, char)\n",
        "          x[i, t, char_indices[char]] = 1\n",
        "      y[i, char_indices[next_chars[i]]] = 1\n",
        "      # print(char_indices['A'])\n",
        "      # print(x[0][0])\n",
        "      # print(char_indices['W'])\n",
        "      # print(y[0])\n",
        "      # test = 2"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus length: 1940271\n",
            "Total chars: 108\n",
            "108\n",
            "Number of sequences: 646744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56lo6q1tIlVH"
      },
      "source": [
        "* `text` is a list of characters from data. `text[0]` = `w`, `text[:5]` = `We re`\r\n",
        "* `sentences` is a list of sentences of length `maxlen` from data `text`, incremented by `step` \r\n",
        "    * `sentences[0]` : We report spectroscopic observations of | `next_char[0]` : A\r\n",
        "    * `sentences[1]` : report spectroscopic observations of AT2 | `next_char[1]` : 0\r\n",
        "    * `sentences[2]` : ort spectroscopic observations of AT2018 | `next_char[2]` : 1\r\n",
        "* `x.shape` (646744, 40, 108) -> (num of sequences, length of sequence, number of characters) \r\n",
        "* `y.shape` (646744, 108) -> (num of sequences, number of characters)\r\n",
        "\r\n",
        "\r\n",
        "Full Explanation of For Loop\r\n",
        "  \r\n",
        "i, sentence: `0 We report spectroscopic observations of`\r\n",
        "\r\n",
        "t, char: `0 W`\r\n",
        "\r\n",
        "`char_indices['W']` = 56\r\n",
        "\r\n",
        "`x[0][0]` : \r\n",
        "\r\n",
        "```\r\n",
        "[False False False False False False False False False False False False\r\n",
        " False False False False False False False False False False False False\r\n",
        " False False False False False False False False False False False False\r\n",
        " False False False False False False False False False False False False\r\n",
        " False False False False False False False False  True False False False\r\n",
        " False False False False False False False False False False False False\r\n",
        " False False False False False False False False False False False False\r\n",
        " False False False False False False False False False False False False\r\n",
        " False False False False False False False False False False False False]\r\n",
        "```\r\n",
        "\r\n",
        "next_char is 'A', `char_indices['A']` = 34.\r\n",
        "\r\n",
        "`y[0]` :\r\n",
        "\r\n",
        "```\r\n",
        "[False False False False False False False False False False False False\r\n",
        " False False False False False False False False False False False False\r\n",
        " False False False False False False False False False False  True False\r\n",
        " False False False False False False False False False False False False\r\n",
        " False False False False False False False False False False False False\r\n",
        " False False False False False False False False False False False False\r\n",
        " False False False False False False False False False False False False\r\n",
        " False False False False False False False False False False False False\r\n",
        " False False False False False False False False False False False False]\r\n",
        "```\r\n",
        "\r\n",
        "\r\n",
        "  \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo8Rr0jZjag5"
      },
      "source": [
        "# Build the model: a single LSTM layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY6swYiwjag6"
      },
      "source": [
        "model = keras.Sequential( # stack layers into tf.keras.Model.\n",
        "    [ # this is the first layer\n",
        "     \n",
        "        keras.Input(shape=(maxlen, len(chars))), # instatntiate Keras tensor of shape (40, 180)\n",
        "        layers.LSTM(128), # 128 is the dimensionality of output space\n",
        "        layers.Dense(len(chars), activation=\"softmax\"), # densely connected NN layer with output of dimension 40 & softmax activation function.\n",
        "    ], \n",
        "    # [ # this is the first layer\n",
        "     \n",
        "    #     layers.LSTM(128), # 128 is the dimensionality of output space\n",
        "    #     layers.Dense(len(chars), activation=\"softmax\"), # densely connected NN layer with output of dimension 40 & softmax activation function.\n",
        "    # ]\n",
        ")\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer) # configure the losses and optimizer "
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99SZslcLMaeK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "514563ca-51e4-4da1-b450-ae6357d29c39"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"[<tensorflow.python.keras.layers.recurrent_v2.LSTM object at 0x7f9a36db82b0>, <tensorflow.python.keras.layers.core.Dense object at 0x7f9a365cc470>]\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_8 (LSTM)                (None, 128)               121344    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 108)               13932     \n",
            "=================================================================\n",
            "Total params: 135,276\n",
            "Trainable params: 135,276\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ-M4y0bjag6"
      },
      "source": [
        "# Prepare the text sampling function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNMsMuQAjag6"
      },
      "source": [
        "# returns the index of the most likely value -> 'maximum' preds value \n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    # print(\"after changing to np array\")\n",
        "    # print(preds)\n",
        "    preds = np.log(preds) / temperature # why do this?\n",
        "    # print(\"after log and / temp\")\n",
        "    # print(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds) # why do this? normalize?\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    # print(\"Probas:\")\n",
        "    # print(probas)\n",
        "    # print(\"returned values: \", np.argmax(probas))\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZUsG58Djag7"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCLKmowrAe3r",
        "outputId": "3c3109a3-d902-4837-8ee8-0ca8ebe0f005",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 1\r\n",
        "batch_size = 128\r\n",
        "\r\n",
        "for epoch in range(epochs):\r\n",
        "    model.fit(x, y, batch_size=batch_size, epochs=1) # train the model\r\n",
        "    print()\r\n",
        "    print(\"Generating text after epoch: %d\" % epoch)\r\n",
        "\r\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\r\n",
        "    print(f\"text len {len(text)} start_index {start_index}, maxlen {maxlen}\")\r\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\r\n",
        "        print(\"...Diversity:\", diversity)\r\n",
        "\r\n",
        "        # generated = \"\"\r\n",
        "        test_generated = []\r\n",
        "        topthree = []\r\n",
        "        sentence = text[start_index : start_index + maxlen]\r\n",
        "        print('...Generating with seed: \"' + sentence + '\"')\r\n",
        "\r\n",
        "        for a in range(3):\r\n",
        "          generated = \"\"\r\n",
        "          for i in range(20):\r\n",
        "            # if i == 0:\r\n",
        "              x_pred = np.zeros((1, maxlen, len(chars))) # this is 1 row of same dimesion with x\r\n",
        "              for t, char in enumerate(sentence): \r\n",
        "                  x_pred[0, t, char_indices[char]] = 1.0 # map True value on x_pred based on 'sentence'\r\n",
        "              preds = model.predict(x_pred, verbose=0)[0]\r\n",
        "              # print(preds.shape)\r\n",
        "              # print(preds)\r\n",
        "              next_index = sample(preds, diversity) # calls the sample(preds, temperature) fn above\r\n",
        "              next_char = indices_char[next_index]\r\n",
        "              if (i == 0): topthree.append(next_char)\r\n",
        "              sentence = sentence[1:] + next_char\r\n",
        "              generated += next_char\r\n",
        "          test_generated.append(generated)\r\n",
        "\r\n",
        "        print(\"...Generated: \", test_generated[0])\r\n",
        "        print(f\"{test_generated[1]}\\n{test_generated[2]}\")\r\n",
        "        print(\"top Three:\", topthree)\r\n",
        "        print()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5053/5053 [==============================] - 24s 5ms/step - loss: 1.2412\n",
            "\n",
            "Generating text after epoch: 0\n",
            "text len 1940271 start_index 1767214, maxlen 40\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \" al. 1995 AJ, 110, 880), and a redshift \"\n",
            "...Generated:  of the observations \n",
            "of the program the p\n",
            "rogram is and the so\n",
            "top Three: ['o', 'o', 'r']\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \" al. 1995 AJ, 110, 880), and a redshift \"\n",
            "...Generated:  from the propomence \n",
            "of the first about t\n",
            "he first of the two \n",
            "top Three: ['f', 'o', 'h']\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \" al. 1995 AJ, 110, 880), and a redshift \"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "...Generated:  is rereooum enfi8q.:\n",
            " We Ales anc program\n",
            " mapiling eeal usrem\n",
            "top Three: ['i', ' ', ' ']\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \" al. 1995 AJ, 110, 880), and a redshift \"\n",
            "...Generated:  limit unchouscom we \n",
            "solutin. relea used \n",
            "ampimetionREOO=Hahla\n",
            "top Three: ['l', 's', 'a']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHAGMHmJdDTX",
        "outputId": "cb424c38-e981-477f-a638-2b0ab232ea5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input = \"That’s one small ste\"\r\n",
        "for t, char in enumerate(input):\r\n",
        "  print(f\"{t}, {char}\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0, T\n",
            "1, h\n",
            "2, a\n",
            "3, t\n",
            "4, ’\n",
            "5, s\n",
            "6,  \n",
            "7, o\n",
            "8, n\n",
            "9, e\n",
            "10,  \n",
            "11, s\n",
            "12, m\n",
            "13, a\n",
            "14, l\n",
            "15, l\n",
            "16,  \n",
            "17, s\n",
            "18, t\n",
            "19, e\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}